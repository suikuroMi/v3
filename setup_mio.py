import os
import sys
import subprocess
import platform
import shutil

# CONFIGURATION
REQUIRED_PYTHON = "3.10"
REQUIRED_MODELS = ["qwen2.5:7b", "llava:latest"]

# --- ADDED yt-dlp HERE ---
PIP_REQUIREMENTS = [
    "pyside6",
    "ollama",
    "Pillow",
    "pyautogui",
    "psutil",
    "pyperclip",
    "requests",
    "yt-dlp" 
]

def run_command(command, shell=False):
    """Runs a shell command and prints output."""
    print(f"‚öôÔ∏è Running: {' '.join(command) if isinstance(command, list) else command}")
    try:
        subprocess.check_call(command, shell=shell)
        return True
    except subprocess.CalledProcessError:
        print("‚ùå Command failed.")
        return False

def check_ollama():
    """Checks if Ollama is installed and running."""
    print("\nüîç Checking AI Core (Ollama)...")
    if shutil.which("ollama") is None:
        print("‚ùå Ollama is not found in PATH.")
        print("üëâ Please install it from https://ollama.com/")
        return False
    
    # Try to connect
    try:
        import requests
        response = requests.get("http://localhost:11434/")
        if response.status_code == 200:
            print("‚úÖ Ollama is running.")
            return True
    except:
        print("‚ö†Ô∏è Ollama is installed but not running.")
        print("üëâ Please start Ollama first!")
        return False
    return False

def install_python_deps():
    """Installs pip packages."""
    print("\nüì¶ Installing Python Dependencies...")
    cmd = [sys.executable, "-m", "pip", "install"] + PIP_REQUIREMENTS
    run_command(cmd)

def pull_models():
    """Tells Ollama to download the brains."""
    print("\nüß† Downloading AI Models (this may take a while)...")
    for model in REQUIRED_MODELS:
        print(f"‚¨áÔ∏è Pulling {model}...")
        run_command(["ollama", "pull", model])

def main():
    print("=== üê∫ OOKAMI MIO V3 SETUP WIZARD ===")
    
    # 1. Check OS
    os_name = platform.system()
    print(f"üñ•Ô∏è Detected OS: {os_name}")
    
    # 2. Install Dependencies (Includes yt-dlp now)
    install_python_deps()
    
    # 3. Check Ollama
    if check_ollama():
        pull_models()
    else:
        print("‚ö†Ô∏è Skipping model download (Ollama issue). Run 'ollama pull qwen2.5:7b' manually later.")

    # 4. Finalize
    print("\n‚úÖ Setup Complete!")
    print("To start Mio, run: python src/main.py")

if __name__ == "__main__":
    main()